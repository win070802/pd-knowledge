const { db } = require('../../database');
const { pool } = require('../config/database');
const storageService = require('../../services/storage-service');
const GeminiAiService = require('../services/ai/geminiAiService');

// Learn from free text input - Fully AI-Autonomous
const learnFromText = async (req, res) => {
  try {
    const { 
      text, 
      question, 
      answer,
      keywords 
    } = req.body;

    if (!text && !(question && answer)) {
      return res.status(400).json({
        error: 'Either "text" or both "question" and "answer" are required'
      });
    }

    let knowledgeEntries = [];

    if (text) {
      // Fully autonomous AI processing - no manual input needed
      const aiService = new GeminiAiService();
      console.log(`ðŸ¤– AI analyzing text autonomously: "${text.substring(0, 50)}..."`);
      
      const analysisResult = await analyzeTextAutonomously(text, aiService);
      console.log(`ðŸ§  AI autonomous analysis completed - generated ${analysisResult.entries.length} knowledge entries`);
      
             // Process each entry with detected company and category
       for (const entry of analysisResult.entries) {
         const processedEntry = await processAutonomousKnowledgeEntry(entry, analysisResult.detectedCompany, analysisResult.detectedCategory, aiService);
         knowledgeEntries.push(processedEntry);
       }
      
    } else {
      // Direct Q&A input (fallback for manual entry)
      const finalKeywords = keywords || extractKeywords(question + ' ' + answer);
      
    const knowledge = await db.createKnowledge({
        companyId: null, // Will be detected later if needed
        question: question,
        answer: answer,
      keywords: finalKeywords,
        category: 'General',
      isActive: true
    });

      knowledgeEntries.push(knowledge);
    }

    console.log(`ðŸ“š AI autonomously processed and saved ${knowledgeEntries.length} knowledge entries`);

    res.status(201).json({
      success: true,
      message: `AI successfully analyzed and added ${knowledgeEntries.length} knowledge entries autonomously`,
      analysis: {
        detectedCompany: knowledgeEntries[0]?.company_detected || 'Not detected',
        detectedCategory: knowledgeEntries[0]?.category || 'General',
        entriesGenerated: knowledgeEntries.length,
        hasHistoricalUpdates: knowledgeEntries.some(k => k.isHistoricalUpdate)
      },
      knowledge: knowledgeEntries.map(k => ({
        id: k.id,
        company: k.company_detected || null,
        question: k.question,
        answer: k.answer.length > 100 ? k.answer.substring(0, 100) + '...' : k.answer,
        category: k.category,
        keywordsCount: k.keywords?.length || 0,
        isHistoricalUpdate: k.isHistoricalUpdate || false
      }))
    });

  } catch (error) {
    console.error('Error in fully autonomous learn API:', error);
    res.status(500).json({
      error: 'Failed to autonomously process and add knowledge',
      details: error.message
    });
  }
};

// Fully autonomous AI text analysis - detects company, category, and generates Q&A
async function analyzeTextAutonomously(text, aiService) {
  try {
    const autonomousPrompt = `
PhÃ¢n tÃ­ch SIÃŠU THÃ”NG MINH Ä‘oáº¡n text phá»©c táº¡p sau. Báº¡n cáº§n:
1. Tá»° Äá»˜NG PHÃT HIá»†N CÃ”NG TY tá»« text (PDH, PDI, PDE, PDHH, RH...)
2. Tá»° Äá»˜NG PHÃ‚N LOáº I CATEGORY (Leadership, HR, Finance, Operations, IT, Legal, General...)
3. Táº O NHIá»€U Cáº¶P Q&A THÃ”NG MINH - bao gá»“m Cáº¢ Sá» LÆ¯á»¢NG, DANH SÃCH, VAI TRÃ’, THÃ”NG TIN CHI TIáº¾T

TEXT INPUT: "${text}"

YÃŠU Cáº¦U PHÃ‚N TÃCH SIÃŠU THÃ”NG MINH:
- Detect company: TÃ¬m mÃ£ cÃ´ng ty trong text (PDH, PDI, PDE, PDHH, RH...) hoáº·c null náº¿u khÃ´ng cÃ³
- Classify category: IT=cÃ´ng nghá»‡, Leadership=lÃ£nh Ä‘áº¡o/CXO, HR=nhÃ¢n sá»±, Finance=tÃ i chÃ­nh, Operations=váº­n hÃ nh, Legal=phÃ¡p lÃ½, General=khÃ¡c
- Generate COMPREHENSIVE Q&A: Tá»« 1 text â†’ táº¡o ra Táº¤T Cáº¢ cÃ¢u há»i cÃ³ thá»ƒ:
  * Sá»‘ lÆ°á»£ng: "Team X cÃ³ máº¥y ngÆ°á»i?" 
  * Danh sÃ¡ch: "Team X cÃ³ ai?"
  * Vai trÃ² cá»¥ thá»ƒ: "Ai lÃ  CIO/CEO/trÆ°á»Ÿng phÃ²ng?"
  * ThÃ´ng tin chi tiáº¿t: "Nguyá»…n VÄƒn A lÃ m gÃ¬?"
  * So sÃ¡nh: "Ai quáº£n lÃ½ háº¡ táº§ng?"

VÃ Dá»¤ PHÃ‚N TÃCH SIÃŠU THÃ”NG MINH:
Text: "ban cÃ´ng nghá»‡ thÃ´ng tin pdh gá»“m cÃ³ 4 ngÆ°á»i lÃ  lÃª nguyá»…n hoÃ ng minh (cio), nguyá»…n Ä‘á»©c doanh (trÆ°á»Ÿng bá»™ pháº­n háº¡ táº§ng), tráº§n minh khÃ´i (nhÃ¢n viÃªn it), nguyá»…n quang Ä‘á»£i (chuyÃªn viÃªn pháº§n má»m)"
â†’ Company: "PDH"  
â†’ Category: "IT"
â†’ Generate 8-10 Q&A pairs covering:
  â€¢ Sá»‘ lÆ°á»£ng: "Team IT PDH cÃ³ máº¥y ngÆ°á»i?" â†’ "4 ngÆ°á»i"
  â€¢ Danh sÃ¡ch: "Team IT PDH cÃ³ ai?" â†’ "LÃª Nguyá»…n HoÃ ng Minh (CIO), Nguyá»…n Äá»©c Doanh (trÆ°á»Ÿng bá»™ pháº­n háº¡ táº§ng)..."
  â€¢ Vai trÃ²: "Ai lÃ  CIO PDH?" â†’ "LÃª Nguyá»…n HoÃ ng Minh"
  â€¢ Chi tiáº¿t: "Nguyá»…n Äá»©c Doanh lÃ m gÃ¬?" â†’ "TrÆ°á»Ÿng bá»™ pháº­n quáº£n lÃ½ háº¡ táº§ng vÃ  báº£o máº­t"

FORMAT TRáº¢ Lá»œI:
{
  "detectedCompany": "PDH",
  "detectedCategory": "IT", 
  "confidence": {
    "company": 0.98,
    "category": 0.95
  },
  "entries": [
    {
      "question": "Team IT cá»§a PDH cÃ³ bao nhiÃªu ngÆ°á»i?",
      "answer": "Team IT cá»§a PDH cÃ³ 4 ngÆ°á»i.",
      "type": "count_query",
      "keywords": ["team", "IT", "PDH", "4 ngÆ°á»i", "sá»‘ lÆ°á»£ng"],
      "relatedQuestions": ["Ban cÃ´ng nghá»‡ thÃ´ng tin PDH cÃ³ máº¥y thÃ nh viÃªn?"]
    },
    {
      "question": "Team IT cá»§a PDH cÃ³ nhá»¯ng ai?",
      "answer": "Team IT cá»§a PDH gá»“m cÃ³ LÃª Nguyá»…n HoÃ ng Minh (CIO), Nguyá»…n Äá»©c Doanh (trÆ°á»Ÿng bá»™ pháº­n háº¡ táº§ng vÃ  báº£o máº­t), Tráº§n Minh KhÃ´i (nhÃ¢n viÃªn cÃ´ng nghá»‡ thÃ´ng tin), Nguyá»…n Quang Äá»£i (chuyÃªn viÃªn cao cáº¥p phÃ¡t triá»ƒn pháº§n má»m).",
      "type": "list_query",
      "keywords": ["team", "IT", "PDH", "danh sÃ¡ch", "thÃ nh viÃªn"],
      "relatedQuestions": ["Danh sÃ¡ch nhÃ¢n viÃªn IT PDH?"]
    },
    {
      "question": "Ai lÃ  CIO cá»§a PDH?",
      "answer": "CIO cá»§a PDH lÃ  LÃª Nguyá»…n HoÃ ng Minh.",
      "type": "role_query",
      "keywords": ["CIO", "PDH", "LÃª Nguyá»…n HoÃ ng Minh"],
      "relatedQuestions": ["LÃª Nguyá»…n HoÃ ng Minh giá»¯ chá»©c vá»¥ gÃ¬?"]
    }
  ]
}

QUAN TRá»ŒNG: Táº¡o ra Ã­t nháº¥t 6-8 Q&A pairs cho má»—i text phá»©c táº¡p, bao phá»§ Táº¤T Cáº¢ gÃ³c Ä‘á»™ cÃ¢u há»i cÃ³ thá»ƒ.
CHá»ˆ tráº£ vá» JSON vá»›i format trÃªn, khÃ´ng thÃªm text khÃ¡c:`;

    const result = await aiService.model.generateContent(autonomousPrompt);
    const response = await result.response;
    let analysisText = response.text().trim();
    
    // Clean up response
    analysisText = analysisText.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    console.log(`ðŸ” Autonomous AI Analysis:`, analysisText);
    
    try {
      const parsedResult = JSON.parse(analysisText);
      
      // Validate and set defaults
      return {
        detectedCompany: parsedResult.detectedCompany || null,
        detectedCategory: parsedResult.detectedCategory || 'General',
        confidence: parsedResult.confidence || { company: 0.5, category: 0.5 },
        entries: Array.isArray(parsedResult.entries) ? parsedResult.entries : [parsedResult.entries || createFallbackEntry(text)]
      };
    } catch (parseError) {
      console.warn('âš ï¸ Could not parse autonomous AI response, using fallback');
      return createFallbackAutonomousResult(text);
    }
    
  } catch (error) {
    console.error('âŒ Error in autonomous AI analysis:', error);
    return createFallbackAutonomousResult(text);
  }
}

// Fallback autonomous result if AI analysis fails
function createFallbackAutonomousResult(text) {
  return {
    detectedCompany: null,
    detectedCategory: 'General',
    confidence: { company: 0.1, category: 0.5 },
    entries: [createFallbackEntry(text)]
  };
}

// Create fallback entry for failed analysis
function createFallbackEntry(text) {
  return {
    question: `Kiáº¿n thá»©c tá»« text`,
    answer: text,
    type: 'general',
    keywords: extractKeywords(text),
    relatedQuestions: []
  };
}

// Process autonomous knowledge entry with detected company and category
async function processAutonomousKnowledgeEntry(entry, detectedCompanyCode, detectedCategory, aiService) {
  try {
    // Resolve detected company from database
    let company = null;
    if (detectedCompanyCode) {
      company = await db.getCompanyByCode(detectedCompanyCode.toUpperCase());
      if (company) {
        console.log(`âœ… Detected company "${detectedCompanyCode}" resolved to: ${company.full_name}`);
      } else {
        console.log(`âš ï¸ Detected company "${detectedCompanyCode}" not found in database`);
      }
    }

    // Check if this is an update to existing knowledge
    const existingKnowledge = await findSimilarKnowledge(entry.question, company?.id);
    
    let finalEntry = {
      companyId: company ? company.id : null,
      question: entry.question,
      answer: entry.answer,
      keywords: Array.isArray(entry.keywords) ? entry.keywords : extractKeywords(entry.question + ' ' + entry.answer),
      category: detectedCategory || 'General',
      isActive: true
    };

    // Temporarily disable historical update to focus on new knowledge creation
    if (existingKnowledge && existingKnowledge.length > 0) {
      console.log(`â„¹ï¸ Found ${existingKnowledge.length} similar knowledge entries, but creating new entry for now`);
      // For now, just create new entries without updating old ones
      // TODO: Re-enable historical tracking after fixing database issues
    }

    // Create new knowledge entry
    const savedKnowledge = await db.createKnowledge(finalEntry);
    savedKnowledge.isHistoricalUpdate = finalEntry.isHistoricalUpdate;
    savedKnowledge.company_detected = detectedCompanyCode; // Store detected company for response
    
    // Create related questions as separate entries
    if (entry.relatedQuestions && entry.relatedQuestions.length > 0) {
      for (const relatedQ of entry.relatedQuestions) {
        await db.createKnowledge({
          companyId: company ? company.id : null,
          question: relatedQ,
          answer: entry.answer,
          keywords: finalEntry.keywords,
          category: detectedCategory || 'General',
          isActive: true
        });
      }
    }
    
    return savedKnowledge;
    
  } catch (error) {
    console.error('âŒ Error processing autonomous knowledge entry:', error);
    throw error;
  }
}

// Find similar existing knowledge
async function findSimilarKnowledge(question, companyId) {
  try {
    const client = await pool.connect();
    
    try {
      let query = `
        SELECT * FROM knowledge_base 
        WHERE is_active = true
        AND question ILIKE $1
      `;
      const params = [`%${question.split(' ').slice(-3).join(' ')}%`]; // Search for key words
      
      if (companyId) {
        query += ` AND company_id = $2`;
        params.push(companyId);
      }
      
      const result = await client.query(query, params);
      return result.rows;
    } finally {
      client.release();
    }
  } catch (error) {
    console.error('âŒ Error finding similar knowledge:', error);
    return [];
  }
}

// Handle historical updates with AI assistance
async function handleHistoricalUpdate(newEntry, existingEntries, aiService) {
  try {
    const updatePrompt = `
CÃ³ thÃ´ng tin má»›i cáº§n cáº­p nháº­t. HÃ£y táº¡o cÃ¢u tráº£ lá»i cÃ³ lá»‹ch sá»­:

THÃ”NG TIN CÅ¨:
${existingEntries.map(e => `- ${e.answer}`).join('\n')}

THÃ”NG TIN Má»šI: ${newEntry.answer}

YÃŠU Cáº¦U:
1. Táº¡o cÃ¢u tráº£ lá»i bao gá»“m cáº£ thÃ´ng tin hiá»‡n táº¡i vÃ  lá»‹ch sá»­
2. Sá»­ dá»¥ng format: "Hiá»‡n táº¡i lÃ  X. TrÆ°á»›c Ä‘Ã³ lÃ  Y."
3. ThÃ´ng tin má»›i Ä‘Æ°á»£c Æ°u tiÃªn (lÃ  thÃ´ng tin hiá»‡n táº¡i)
4. ThÃ´ng tin cÅ© thÃ nh lá»‹ch sá»­

VÃ­ dá»¥: "CIO cá»§a PDH hiá»‡n táº¡i lÃ  Ã´ng LÃª Nguyá»…n HoÃ ng Minh. TrÆ°á»›c Ä‘Ã³ lÃ  Ã´ng Nguyá»…n VÄƒn A."

CHá»ˆ tráº£ vá» cÃ¢u tráº£ lá»i, khÃ´ng thÃªm text khÃ¡c:`;

    const result = await aiService.model.generateContent(updatePrompt);
    const response = await result.response;
    const updatedAnswer = response.text().trim();
    
    return {
      answer: updatedAnswer,
      hasHistory: true
    };
    
  } catch (error) {
    console.error('âŒ Error creating historical update:', error);
    return {
      answer: newEntry.answer,
      hasHistory: false
    };
  }
}

// Learn document-company mapping and reorganize file
const learnDocumentCompany = async (req, res) => {
  try {
    const { 
      documentId,
      filename, 
      companyCode,
      pattern // Optional: specific pattern to learn
    } = req.body;

    if (!companyCode) {
      return res.status(400).json({
        success: false,
        error: 'Company code is required'
      });
    }

    // Validate company
    const company = await db.getCompanyByCode(companyCode.toUpperCase());
    if (!company) {
      return res.status(400).json({
        success: false,
        error: `Company with code "${companyCode}" not found. Valid codes: PDH, PDI`
      });
    }

    let document = null;

    // Find document by ID or filename
    if (documentId) {
      document = await db.getDocumentById(documentId);
    } else if (filename) {
      // Find document by original filename
      const documents = await db.getDocuments();
      document = documents.find(doc => 
        doc.original_name === filename || 
        doc.original_name.includes(filename) ||
        filename.includes(doc.original_name)
      );
    }

    if (!document) {
      return res.status(404).json({
        success: false,
        error: `Document not found. Available documents: ${documentId ? 'Check document ID' : 'Check filename'}`
      });
    }

    console.log(`ðŸ“š Learning: Document "${document.original_name}" belongs to ${company.code}`);

    // Reorganize file if currently in UNKNOWN folder
    let reorganizeResult = null;
    if (!document.company_id || document.metadata?.companyCode === 'UNKNOWN') {
      
      console.log(`ðŸ”„ Reorganizing document from UNKNOWN to ${company.code}`);
      
      reorganizeResult = await storageService.reorganizeFileByCompany(
        document.file_path,
        document.filename,
        company,
        document.category
      );

      if (reorganizeResult) {
        // Update document in database
        await db.updateDocument(document.id, {
          company_id: company.id,
          file_path: reorganizeResult.path,
          metadata: {
            ...document.metadata,
            companyCode: company.code,
            storageUrl: reorganizeResult.url,
            reorganizedAt: new Date().toISOString(),
            reorganizedFrom: 'UNKNOWN',
            learnedMapping: true
          }
        });

        console.log(`âœ… Document reorganized to ${company.code}/${document.category}/`);
      }
    } else {
      console.log(`â„¹ï¸ Document already assigned to company, updating mapping only`);
    }

    // Learn filename pattern for future auto-detection
    if (pattern || document.original_name) {
      const filenamePattern = pattern || document.original_name;
      
      // Extract meaningful patterns
      const patterns = extractFilenamePatterns(filenamePattern);
      
      // Add patterns to company keywords (only update keywords, not other fields)
      const currentKeywords = company.keywords || [];
      const newKeywords = [...new Set([...currentKeywords, ...patterns])];
      
      // Only update keywords to avoid null constraint issues
      const client = await pool.connect();
      try {
        await client.query(
          'UPDATE companies SET keywords = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
          [newKeywords, company.id]
        );
      } finally {
        client.release();
      }

      console.log(`ðŸ“ Learned patterns: ${patterns.join(', ')} for ${company.code}`);
    }

    res.json({
      success: true,
      message: `Successfully learned that "${document.original_name}" belongs to ${company.code}`,
      document: {
        id: document.id,
        originalName: document.original_name,
        previousCompany: document.metadata?.companyCode || 'UNKNOWN',
        newCompany: company.code,
        category: document.category,
        reorganized: !!reorganizeResult,
        newPath: reorganizeResult ? reorganizeResult.path : document.file_path
      },
      learnedPatterns: pattern ? extractFilenamePatterns(pattern) : extractFilenamePatterns(document.original_name)
    });

  } catch (error) {
    console.error('Error in learnDocumentCompany:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
};

// Get learned knowledge
const getKnowledge = async (req, res) => {
  try {
    const { companyCode, category, limit = 50 } = req.query;
    console.log(`ðŸ” Getting knowledge for: companyCode=${companyCode}, category=${category}, limit=${limit}`);
    
    let filters = { isActive: true };
    
    if (companyCode) {
      const company = await db.getCompanyByCode(companyCode.toUpperCase());
      console.log(`ðŸ“Š Found company:`, company);
      if (company) {
        filters.companyId = company.id;
      }
    }
    
    if (category) {
      filters.category = category;
    }

    console.log(`ðŸŽ¯ Final filters:`, filters);
    
    // Get knowledge directly from database
    const knowledge = await getKnowledgeWithCompany(filters, limit);
    console.log(`ðŸ“š Retrieved ${knowledge.length} knowledge entries`);

    res.json({
      success: true,
      count: knowledge.length,
      knowledge: knowledge.map(k => ({
        id: k.id,
        company: k.company_code || null,
        question: k.question,
        answer: k.answer.substring(0, 200) + (k.answer.length > 200 ? '...' : ''),
        category: k.category,
        keywords: k.keywords,
        createdAt: k.created_at
      }))
    });

  } catch (error) {
    console.error('Error getting knowledge:', error);
    res.status(500).json({
      error: 'Failed to retrieve knowledge',
      details: error.message
    });
  }
};

// Get knowledge with company information
async function getKnowledgeWithCompany(filters, limit) {
  const client = await pool.connect();
  
  try {
    let query = `
      SELECT kb.*, c.code as company_code 
      FROM knowledge_base kb 
      LEFT JOIN companies c ON kb.company_id = c.id 
      WHERE kb.is_active = true
    `;
    const params = [];
    let paramCount = 0;
    
    if (filters.companyId) {
      paramCount++;
      query += ` AND kb.company_id = $${paramCount}`;
      params.push(filters.companyId);
    }
    
    if (filters.category) {
      paramCount++;
      query += ` AND kb.category = $${paramCount}`;
      params.push(filters.category);
    }
    
    query += ` ORDER BY kb.created_at DESC LIMIT $${paramCount + 1}`;
    params.push(limit);
    
    console.log(`ðŸ”Ž Executing query:`, query);
    console.log(`ðŸ“‹ With params:`, params);
    
    const result = await client.query(query, params);
    console.log(`ðŸ“Š Query result: ${result.rows.length} rows`);
    return result.rows;
  } catch (error) {
    console.error('âŒ Error in getKnowledgeWithCompany:', error);
    throw error;
  } finally {
    client.release();
  }
}

// Extract keywords from text (simple implementation)
function extractKeywords(text) {
  if (!text) return [];
  
  const vietnameseStopWords = [
    'vÃ ', 'cá»§a', 'trong', 'vá»›i', 'cho', 'vá»', 'tá»«', 'khi', 'Ä‘áº¿n', 'cÃ³', 'lÃ ', 'má»™t', 
    'cÃ¡c', 'nhá»¯ng', 'nÃ y', 'Ä‘Ã³', 'Ä‘Æ°á»£c', 'sáº½', 'Ä‘á»ƒ', 'theo', 'nhÆ°', 'trÃªn', 'dÆ°á»›i'
  ];
  
  const words = text.toLowerCase()
    .replace(/[^\w\sÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘]/g, ' ')
    .split(/\s+/)
    .filter(word => 
      word.length > 2 && 
      !vietnameseStopWords.includes(word) &&
      !word.match(/^\d+$/)
    );
  
  // Get unique words and limit to 10
  return [...new Set(words)].slice(0, 10);
}

// Extract meaningful patterns from filename for learning
function extractFilenamePatterns(filename) {
  const patterns = [];
  
  // Extract common patterns
  const lowerFilename = filename.toLowerCase();
  
  // Pattern 1: Prefix patterns (QT.01, PDI-XX, etc.)
  const prefixMatch = filename.match(/^([A-Z]{2,4}[\.\-_]?\d*)/i);
  if (prefixMatch) {
    patterns.push(prefixMatch[1].toLowerCase());
  }
  
  // Pattern 2: Specific keywords
  const keywords = [
    'qt', 'quy trinh', 'quy dinh', 'lsx', 'nhl', 
    'soan', 'chuyen', 'luu', 'van ban'
  ];
  
  keywords.forEach(keyword => {
    if (lowerFilename.includes(keyword)) {
      patterns.push(keyword);
    }
  });
  
  // Pattern 3: Date patterns (200524 = DDMMYY)
  const dateMatch = filename.match(/(\d{6})/);
  if (dateMatch) {
    patterns.push('date_pattern');
  }
  
  return [...new Set(patterns)]; // Remove duplicates
}

module.exports = {
  learnFromText,
  getKnowledge,
  learnDocumentCompany
}; 
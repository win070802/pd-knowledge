const { ImageAnnotatorClient } = require('@google-cloud/vision');
const { convert } = require('pdf2pic');
const fs = require('fs');
const path = require('path');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { db } = require('./database');
require('dotenv').config();

class VisionOCRService {
  constructor() {
    this.tempDir = './temp-images';
    this.ensureTempDir();
    
    // Initialize Google Cloud Vision
    this.visionClient = new ImageAnnotatorClient({
      keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
      projectId: process.env.GOOGLE_CLOUD_PROJECT_ID
    });
    
    // Initialize Gemini AI for text correction and content analysis
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    this.model = this.genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
  }

  ensureTempDir() {
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }
  }

  // Check if PDF is likely scanned (has very little text)
  isScannedPDF(extractedText) {
    if (!extractedText || extractedText.trim().length < 100) {
      return true;
    }
    
    // Check if text is mostly whitespace or special characters
    const meaningfulText = extractedText.replace(/\s+/g, '').replace(/[^a-zA-ZÃ€-á»¹0-9]/g, '');
    return meaningfulText.length < 50;
  }

  // Convert PDF to images with high quality settings
  async convertPDFToImages(pdfPath, maxPages = 10) {
    try {
      const options = {
        density: 300,           // High DPI for Vision API
        saveFilename: "page",
        savePath: this.tempDir,
        format: "png",
        quality: 100,
        width: 2000,           // Good resolution for Vision API
        graphicsmagick: true
      };

      console.log(`ðŸ“· Converting PDF to images for Vision API (max ${maxPages} pages)...`);
      
      const convert = require('pdf2pic').fromPath(pdfPath, options);
      const results = [];
      
      for (let i = 1; i <= maxPages; i++) {
        try {
          const result = await convert(i, { responseType: "image" });
          
          if (result && result.path) {
            results.push(result);
            console.log(`âœ… Converted page ${i}: ${result.path}`);
          } else {
            console.log(`âŒ No result for page ${i}`);
            break;
          }
        } catch (error) {
          console.log(`âŒ Error converting page ${i}:`, error.message);
          if (i === 1) {
            // Try bulk conversion
            try {
              const bulkResults = await convert.bulk(-1, { responseType: "image" });
              return bulkResults.slice(0, maxPages);
            } catch (bulkError) {
              console.log(`âŒ Bulk conversion failed:`, bulkError.message);
            }
          }
          break;
        }
      }

      return results;
    } catch (error) {
      console.error('Error converting PDF to images:', error);
      throw error;
    }
  }

  // Extract text from image using Google Cloud Vision
  async extractTextFromImage(imagePath) {
    try {
      console.log(`ðŸ” Extracting text from image using Vision API: ${imagePath}`);
      
      const [result] = await this.visionClient.textDetection(imagePath);
      const detections = result.textAnnotations;
      
      if (!detections || detections.length === 0) {
        console.log('No text detected in image');
        return '';
      }
      
      // First detection contains the full text
      const fullText = detections[0].description;
      
      console.log(`âœ… Vision API extracted ${fullText.length} characters`);
      return fullText;
      
    } catch (error) {
      console.error('Error in Vision API OCR:', error);
      return '';
    }
  }

  // Correct OCR text using AI with enhanced Vietnamese support
  async correctOCRText(rawText) {
    try {
      if (!rawText || rawText.trim().length < 10) {
        return rawText;
      }

      console.log(`ðŸ”§ Correcting OCR text (${rawText.length} characters) with AI...`);
      
      const prompt = `
Báº¡n lÃ  chuyÃªn gia sá»­a chÃ­nh táº£ vÃ  cáº£i thiá»‡n vÄƒn báº£n tiáº¿ng Viá»‡t tá»« OCR. Nhiá»‡m vá»¥:

NGUYÃŠN Táº®C:
1. CHá»ˆ sá»­a lá»—i chÃ­nh táº£, dáº¥u thanh vÃ  nháº­n dáº¡ng sai
2. KHÃ”NG thay Ä‘á»•i ná»™i dung, Ã½ nghÄ©a hoáº·c cáº¥u trÃºc
3. Giá»¯ nguyÃªn format, sá»‘ liá»‡u, ngÃ y thÃ¡ng
4. Sá»­a tÃªn cÃ´ng ty, chá»©c vá»¥ náº¿u bá»‹ sai
5. Cáº£i thiá»‡n kháº£ nÄƒng Ä‘á»c nhÆ°ng giá»¯ nguyÃªn thÃ´ng tin

CÃC Lá»–I THÆ¯á»œNG Gáº¶P:
- Dáº¥u thanh tiáº¿ng Viá»‡t: "nhan su" â†’ "nhÃ¢n sá»±"
- Chá»¯ hoa/thÆ°á»ng: "CONG TY" â†’ "CÃ”NG TY"
- KÃ½ tá»± Ä‘áº·c biá»‡t: "Â§" â†’ "Äiá»u", "Â¢" â†’ "ChÆ°Æ¡ng"
- TÃªn cÃ´ng ty: "PHAT DAT" â†’ "PHÃT Äáº T"
- Chá»©c vá»¥: "GIAM DOC" â†’ "GIÃM Äá»C"

VÄ‚N Báº¢N Cáº¦N Sá»¬A:
${rawText}

VÄ‚N Báº¢N ÄÃƒ Sá»¬A:`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let correctedText = response.text().trim();
      
      // Clean up AI response
      if (correctedText.includes('VÄ‚N Báº¢N ÄÃƒ Sá»¬A:')) {
        correctedText = correctedText.split('VÄ‚N Báº¢N ÄÃƒ Sá»¬A:')[1].trim();
      }
      
      // Safety check
      if (!correctedText || correctedText.length < rawText.length * 0.3) {
        console.log('âš ï¸ Correction result too short, using original text');
        return rawText;
      }
      
      console.log(`âœ… Text correction completed: ${rawText.length} â†’ ${correctedText.length} chars`);
      return correctedText;
      
    } catch (error) {
      console.error('âŒ Error correcting OCR text:', error);
      return rawText;
    }
  }

  // Classify document content to detect inappropriate or junk files
  async classifyDocumentContent(text, filename = '') {
    try {
      console.log(`ðŸ” Classifying document content...`);
      
      const prompt = `
Báº¡n lÃ  chuyÃªn gia phÃ¢n loáº¡i tÃ i liá»‡u doanh nghiá»‡p. PhÃ¢n tÃ­ch vÄƒn báº£n vÃ  tráº£ lá»i:

TIÃŠU CHÃ CHáº¤P NHáº¬N:
âœ… TÃ i liá»‡u cÃ´ng ty (quy Ä‘á»‹nh, quy trÃ¬nh, chÃ­nh sÃ¡ch)
âœ… BÃ¡o cÃ¡o, biÃªn báº£n há»p
âœ… HÆ°á»›ng dáº«n, sÆ¡ Ä‘á»“ tá»• chá»©c
âœ… Há»£p Ä‘á»“ng, thá»a thuáº­n
âœ… TÃ i liá»‡u tÃ i chÃ­nh, kiá»ƒm toÃ¡n
âœ… VÄƒn báº£n phÃ¡p lÃ½ liÃªn quan cÃ´ng ty

TIÃŠU CHÃ Tá»ª CHá»I:
âŒ Ná»™i dung khÃ´ng liÃªn quan cÃ´ng ty
âŒ TÃ i liá»‡u cÃ¡ nhÃ¢n
âŒ VÄƒn báº£n táº§m báº­y, spam
âŒ Ná»™i dung nháº¡y cáº£m
âŒ File rÃ¡c, test, demo
âŒ Quáº£ng cÃ¡o, marketing khÃ´ng liÃªn quan

FILENAME: ${filename}

CONTENT: ${text.substring(0, 2000)}...

Tráº£ lá»i CHÃNH XÃC theo format:
{
  "accept": true/false,
  "category": "Quy Ä‘á»‹nh|Quy trÃ¬nh|BÃ¡o cÃ¡o|Há»£p Ä‘á»“ng|TÃ i chÃ­nh|KhÃ¡c",
  "confidence": 0.0-1.0,
  "reason": "LÃ½ do ngáº¯n gá»n",
  "businessRelevance": "Má»©c Ä‘á»™ liÃªn quan cÃ´ng ty 0.0-1.0"
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let classificationText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = classificationText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const classification = JSON.parse(jsonMatch[0]);
        console.log(`ðŸ“Š Document classification:`, classification);
        return classification;
      }
      
      // Fallback classification
      return {
        accept: true,
        category: 'KhÃ¡c',
        confidence: 0.5,
        reason: 'Unable to classify automatically',
        businessRelevance: 0.5
      };
      
    } catch (error) {
      console.error('âŒ Error classifying document:', error);
      // Default to accept if classification fails
      return {
        accept: true,
        category: 'KhÃ¡c',
        confidence: 0.3,
        reason: 'Classification error - defaulting to accept',
        businessRelevance: 0.3
      };
    }
  }

  // Check for duplicate documents using content similarity
  async checkForDuplicates(text, filename, companyId = null) {
    try {
      console.log(`ðŸ” Checking for duplicate documents...`);
      
      // Get existing documents from the same company
      let existingDocs = [];
      if (companyId) {
        // Get all documents and filter by company_id
        const allDocs = await db.getDocuments();
        existingDocs = allDocs.filter(doc => doc.company_id === companyId);
      }
      
      if (existingDocs.length === 0) {
        return { isDuplicate: false, similarDocs: [] };
      }
      
      // Use AI to check similarity
      const prompt = `
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng tÃ i liá»‡u. So sÃ¡nh vÄƒn báº£n má»›i vá»›i cÃ¡c tÃ i liá»‡u hiá»‡n cÃ³:

VÄ‚N Báº¢N Má»šI:
Filename: ${filename}
Content: ${text.substring(0, 1500)}...

CÃC TÃ€I LIá»†U HIá»†N CÃ“:
${existingDocs.slice(0, 5).map(doc => `
- ID: ${doc.id}
- Filename: ${doc.original_name}
- Content: ${doc.content_text ? doc.content_text.substring(0, 500) : 'No content'}...
`).join('\n')}

PhÃ¢n tÃ­ch vÃ  tráº£ lá»i theo format JSON:
{
  "isDuplicate": true/false,
  "similarDocs": [
    {
      "id": number,
      "filename": "string",
      "similarity": 0.0-1.0,
      "reason": "LÃ½ do tÆ°Æ¡ng Ä‘á»“ng"
    }
  ],
  "recommendation": "merge|replace|keep_separate",
  "confidenceScore": 0.0-1.0
}

LÆ°u Ã½:
- similarity > 0.8: TrÃ¹ng láº·p cao
- similarity > 0.6: CÃ³ thá»ƒ merge
- similarity < 0.4: KhÃ¡c biá»‡t, giá»¯ riÃªng`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let analysisText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const analysis = JSON.parse(jsonMatch[0]);
        console.log(`ðŸ“Š Duplicate analysis:`, analysis);
        return analysis;
      }
      
      return { isDuplicate: false, similarDocs: [] };
      
    } catch (error) {
      console.error('âŒ Error checking duplicates:', error);
      return { isDuplicate: false, similarDocs: [] };
    }
  }

  // Merge similar documents using AI
  async mergeSimilarDocuments(newText, existingDoc, mergeReason) {
    try {
      console.log(`ðŸ”— Merging similar documents...`);
      
      const prompt = `
Báº¡n lÃ  chuyÃªn gia merge tÃ i liá»‡u. HÃ£y káº¿t há»£p 2 tÃ i liá»‡u sau thÃ nh 1 tÃ i liá»‡u hoÃ n chá»‰nh:

LÃ DO MERGE: ${mergeReason}

TÃ€I LIá»†U HIá»†N CÃ“:
${existingDoc.content_text}

TÃ€I LIá»†U Má»šI:
${newText}

YÃŠU Cáº¦U MERGE:
1. Giá»¯ thÃ´ng tin Ä‘áº§y Ä‘á»§ tá»« cáº£ 2 tÃ i liá»‡u
2. Loáº¡i bá» thÃ´ng tin trÃ¹ng láº·p
3. Sáº¯p xáº¿p theo logic (thá»i gian, má»©c Ä‘á»™ quan trá»ng)
4. ÄÃ¡nh dáº¥u nguá»“n náº¿u cÃ³ thÃ´ng tin xung Ä‘á»™t
5. Giá»¯ format vÃ  cáº¥u trÃºc rÃµ rÃ ng

TÃ€I LIá»†U ÄÃƒ MERGE:`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let mergedText = response.text().trim();
      
      // Clean up AI response
      if (mergedText.includes('TÃ€I LIá»†U ÄÃƒ MERGE:')) {
        mergedText = mergedText.split('TÃ€I LIá»†U ÄÃƒ MERGE:')[1].trim();
      }
      
      console.log(`âœ… Documents merged successfully: ${mergedText.length} characters`);
      return mergedText;
      
    } catch (error) {
      console.error('âŒ Error merging documents:', error);
      return newText; // Return new text if merge fails
    }
  }

  // Analyze document structure and content for Q&A
  async analyzeDocumentStructure(text) {
    try {
      console.log(`ðŸ” Analyzing document structure for Q&A...`);
      
      const prompt = `
PhÃ¢n tÃ­ch cáº¥u trÃºc tÃ i liá»‡u Ä‘á»ƒ há»— trá»£ há»‡ thá»‘ng há»i Ä‘Ã¡p:

CONTENT: ${text.substring(0, 3000)}...

Tráº£ lá»i theo format JSON:
{
  "documentType": "Quy Ä‘á»‹nh|Quy trÃ¬nh|BÃ¡o cÃ¡o|Há»£p Ä‘á»“ng|SÆ¡ Ä‘á»“|KhÃ¡c",
  "mainTopics": ["topic1", "topic2", "topic3"],
  "keyPoints": [
    {
      "section": "Pháº§n nÃ o",
      "content": "Ná»™i dung chÃ­nh",
      "importance": 1-5
    }
  ],
  "procedures": [
    {
      "step": 1,
      "description": "BÆ°á»›c 1",
      "details": "Chi tiáº¿t"
    }
  ],
  "keyTerms": ["term1", "term2"],
  "canAnswerQuestions": [
    "CÃ³ thá»ƒ tráº£ lá»i cÃ¢u há»i gÃ¬?",
    "Quy trÃ¬nh nhÆ° tháº¿ nÃ o?",
    "Ai lÃ  ngÆ°á»i phá»¥ trÃ¡ch?"
  ]
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let analysisText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const analysis = JSON.parse(jsonMatch[0]);
        console.log(`ðŸ“Š Document structure analysis completed`);
        return analysis;
      }
      
      return {
        documentType: 'KhÃ¡c',
        mainTopics: [],
        keyPoints: [],
        procedures: [],
        keyTerms: [],
        canAnswerQuestions: []
      };
      
    } catch (error) {
      console.error('âŒ Error analyzing document structure:', error);
      return {
        documentType: 'KhÃ¡c',
        mainTopics: [],
        keyPoints: [],
        procedures: [],
        keyTerms: [],
        canAnswerQuestions: []
      };
    }
  }

  // Process scanned PDF with Vision API
  async processScannedPDF(pdfPath, maxPages = 10) {
    try {
      console.log('ðŸ” Processing scanned PDF with Vision API...');
      
      // Convert PDF to images
      const images = await this.convertPDFToImages(pdfPath, maxPages);
      
      if (images.length === 0) {
        throw new Error('No images extracted from PDF');
      }

      let allText = '';
      
      // Extract text from each image using Vision API
      for (const image of images) {
        const imagePath = image.path;
        const pageText = await this.extractTextFromImage(imagePath);
        
        if (pageText.trim()) {
          allText += `\n--- Trang ${images.indexOf(image) + 1} ---\n`;
          allText += pageText.trim() + '\n';
        }
        
        // Clean up image file
        if (fs.existsSync(imagePath)) {
          fs.unlinkSync(imagePath);
        }
      }

      console.log(`âœ… Vision API OCR completed. Extracted ${allText.length} characters`);
      
      // Apply AI-powered text correction
      if (allText.trim().length > 0) {
        const correctedText = await this.correctOCRText(allText);
        return correctedText;
      }
      
      return allText;

    } catch (error) {
      console.error('Error processing scanned PDF:', error);
      throw error;
    }
  }

  // Enhanced document processing with all new features
  async processDocumentWithEnhancements(pdfPath, filename, originalName, companyId = null) {
    try {
      console.log(`ðŸš€ Processing document with enhancements: ${originalName}`);
      
      // Step 1: Extract text (standard or OCR)
      const dataBuffer = fs.readFileSync(pdfPath);
      const pdfParse = require('pdf-parse');
      const data = await pdfParse(dataBuffer);
      let extractedText = data.text;
      
      // Use Vision API if standard extraction yields little text
      if (this.isScannedPDF(extractedText)) {
        console.log('ðŸ“¸ Using Vision API for scanned document...');
        extractedText = await this.processScannedPDF(pdfPath);
      }
      
      // Step 2: Classify content
      const classification = await this.classifyDocumentContent(extractedText, originalName);
      
      if (!classification.accept) {
        throw new Error(`Document rejected: ${classification.reason}`);
      }
      
      // Step 3: Check for duplicates
      const duplicateAnalysis = await this.checkForDuplicates(extractedText, originalName, companyId);
      
      // Step 4: Handle duplicates if found
      if (duplicateAnalysis.isDuplicate && duplicateAnalysis.recommendation === 'merge') {
        console.log('ðŸ”— Merging with similar document...');
        const similarDoc = duplicateAnalysis.similarDocs[0];
        const existingDoc = await db.getDocumentById(similarDoc.id);
        
        if (existingDoc) {
          extractedText = await this.mergeSimilarDocuments(
            extractedText, 
            existingDoc, 
            similarDoc.reason
          );
        }
      }
      
      // Step 5: Analyze document structure
      const structureAnalysis = await this.analyzeDocumentStructure(extractedText);
      
      return {
        text: extractedText,
        classification: classification,
        duplicateAnalysis: duplicateAnalysis,
        structureAnalysis: structureAnalysis,
        processingMethod: this.isScannedPDF(data.text) ? 'Vision API OCR' : 'Standard PDF'
      };
      
    } catch (error) {
      console.error('âŒ Error in enhanced document processing:', error);
      throw error;
    }
  }

  // Clean up temporary files
  cleanup() {
    try {
      if (fs.existsSync(this.tempDir)) {
        const files = fs.readdirSync(this.tempDir);
        files.forEach(file => {
          fs.unlinkSync(path.join(this.tempDir, file));
        });
      }
    } catch (error) {
      console.error('Error cleaning up temp files:', error);
    }
  }
}

module.exports = new VisionOCRService(); 
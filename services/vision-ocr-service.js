const { ImageAnnotatorClient } = require('@google-cloud/vision');
const { convert } = require('pdf2pic');
const fs = require('fs');
const path = require('path');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { db } = require('../database');
require('dotenv').config();

class VisionOCRService {
  constructor() {
    this.tempDir = './temp-images';
    this.ensureTempDir();
    
    // Initialize Google Cloud Vision
    // Handle both local (keyFilename) and production (JSON credentials) environments
    let visionConfig = {
      projectId: process.env.GOOGLE_CLOUD_PROJECT_ID
    };

    if (process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON) {
      // Production: Parse JSON credentials from environment variable
      try {
        const credentials = JSON.parse(process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON);
        visionConfig.credentials = credentials;
        console.log('üîë Using JSON credentials for Google Cloud Vision');
      } catch (error) {
        console.error('‚ùå Failed to parse GOOGLE_APPLICATION_CREDENTIALS_JSON:', error);
        throw error;
      }
    } else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      // Local development: Use keyFilename
      visionConfig.keyFilename = process.env.GOOGLE_APPLICATION_CREDENTIALS;
      console.log('üîë Using keyFilename for Google Cloud Vision');
    } else {
      throw new Error('No Google Cloud credentials found. Set either GOOGLE_APPLICATION_CREDENTIALS_JSON or GOOGLE_APPLICATION_CREDENTIALS');
    }

    this.visionClient = new ImageAnnotatorClient(visionConfig);
    
    // Initialize Gemini AI for text correction and content analysis
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    this.model = this.genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
  }

  ensureTempDir() {
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }
  }

  // Check if PDF is likely scanned (has very little text)
  isScannedPDF(extractedText) {
    if (!extractedText || extractedText.trim().length < 100) {
      return true;
    }
    
    // Check if text is mostly whitespace or special characters
    const meaningfulText = extractedText.replace(/\s+/g, '').replace(/[^a-zA-Z√Ä-·ªπ0-9]/g, '');
    return meaningfulText.length < 50;
  }

  // Convert PDF to images with high quality settings
  async convertPDFToImages(pdfPath, maxPages = null) {
    // Use environment variable or default to 50 pages (was 10)
    const pageLimit = maxPages || parseInt(process.env.MAX_PDF_PAGES) || 50;
    try {
      const options = {
        density: 300,           // High DPI for Vision API
        saveFilename: "page",
        savePath: this.tempDir,
        format: "png",
        quality: 100,
        width: 2000,           // Good resolution for Vision API
        graphicsmagick: true
      };

      console.log(`üì∑ Converting PDF to images for Vision API (limit: ${pageLimit} pages)...`);
      
      const convert = require('pdf2pic').fromPath(pdfPath, options);
      const results = [];
      let actualPages = 0;
      
      for (let i = 1; i <= pageLimit; i++) {
        try {
          const result = await convert(i, { responseType: "image" });
          
          if (result && result.path) {
            results.push(result);
            actualPages = i;
            console.log(`‚úÖ Converted page ${i}: ${result.path}`);
          } else {
            console.log(`üìÑ Reached end of PDF at page ${i-1}`);
            break;
          }
        } catch (error) {
          console.log(`‚ùå Error converting page ${i}:`, error.message);
          if (i === 1) {
            // Try bulk conversion
            try {
              console.log(`üîÑ Trying bulk conversion for all pages...`);
              const bulkResults = await convert.bulk(-1, { responseType: "image" });
              const limitedResults = bulkResults.slice(0, pageLimit);
              
              if (bulkResults.length > pageLimit) {
                console.log(`‚ö†Ô∏è  PDF has ${bulkResults.length} pages, processing only first ${pageLimit} pages`);
                console.log(`üí° To process more pages, set MAX_PDF_PAGES environment variable`);
              }
              
              console.log(`‚úÖ Bulk converted ${limitedResults.length} pages`);
              return limitedResults;
            } catch (bulkError) {
              console.log(`‚ùå Bulk conversion failed:`, bulkError.message);
            }
          }
          break;
        }
      }

      // Log conversion summary
      console.log(`üìä PDF conversion completed: ${results.length} pages processed`);
      if (actualPages === pageLimit) {
        console.log(`‚ö†Ô∏è  Reached page limit (${pageLimit}). PDF might have more pages.`);
        console.log(`üí° To process more pages, set MAX_PDF_PAGES environment variable to higher value`);
      }

      return results;
    } catch (error) {
      console.error('Error converting PDF to images:', error);
      throw error;
    }
  }

  // Extract text from image using Google Cloud Vision
  async extractTextFromImage(imagePath) {
    try {
      console.log(`üîç Extracting text from image using Vision API: ${imagePath}`);
      
      const [result] = await this.visionClient.textDetection(imagePath);
      const detections = result.textAnnotations;
      
      if (!detections || detections.length === 0) {
        console.log('No text detected in image');
        return '';
      }
      
      // First detection contains the full text
      const fullText = detections[0].description;
      
      console.log(`‚úÖ Vision API extracted ${fullText.length} characters`);
      return fullText;
      
    } catch (error) {
      console.error('Error in Vision API OCR:', error);
      return '';
    }
  }

  // Correct OCR text using AI with enhanced Vietnamese support
  async correctOCRText(rawText) {
    try {
      if (!rawText || rawText.trim().length < 10) {
        return rawText;
      }

      console.log(`üîß Correcting OCR text (${rawText.length} characters) with AI...`);
      
      const prompt = `
B·∫°n l√† chuy√™n gia s·ª≠a ch√≠nh t·∫£ v√† c·∫£i thi·ªán vƒÉn b·∫£n ti·∫øng Vi·ªát t·ª´ OCR. Nhi·ªám v·ª•:

NGUY√äN T·∫ÆC:
1. CH·ªà s·ª≠a l·ªói ch√≠nh t·∫£, d·∫•u thanh v√† nh·∫≠n d·∫°ng sai
2. KH√îNG thay ƒë·ªïi n·ªôi dung, √Ω nghƒ©a ho·∫∑c c·∫•u tr√∫c
3. Gi·ªØ nguy√™n format, s·ªë li·ªáu, ng√†y th√°ng
4. S·ª≠a t√™n c√¥ng ty, ch·ª©c v·ª• n·∫øu b·ªã sai
5. C·∫£i thi·ªán kh·∫£ nƒÉng ƒë·ªçc nh∆∞ng gi·ªØ nguy√™n th√¥ng tin

C√ÅC L·ªñI TH∆Ø·ªúNG G·∫∂P:
- D·∫•u thanh ti·∫øng Vi·ªát: "nhan su" ‚Üí "nh√¢n s·ª±"
- Ch·ªØ hoa/th∆∞·ªùng: "CONG TY" ‚Üí "C√îNG TY"
- K√Ω t·ª± ƒë·∫∑c bi·ªát: "¬ß" ‚Üí "ƒêi·ªÅu", "¬¢" ‚Üí "Ch∆∞∆°ng"
- T√™n c√¥ng ty: "PHAT DAT" ‚Üí "PH√ÅT ƒê·∫†T"
- Ch·ª©c v·ª•: "GIAM DOC" ‚Üí "GI√ÅM ƒê·ªêC"

VƒÇN B·∫¢N C·∫¶N S·ª¨A:
${rawText}

VƒÇN B·∫¢N ƒê√É S·ª¨A:`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let correctedText = response.text().trim();
      
      // Clean up AI response
      if (correctedText.includes('VƒÇN B·∫¢N ƒê√É S·ª¨A:')) {
        correctedText = correctedText.split('VƒÇN B·∫¢N ƒê√É S·ª¨A:')[1].trim();
      }
      
      // Safety check
      if (!correctedText || correctedText.length < rawText.length * 0.3) {
        console.log('‚ö†Ô∏è Correction result too short, using original text');
        return rawText;
      }
      
      console.log(`‚úÖ Text correction completed: ${rawText.length} ‚Üí ${correctedText.length} chars`);
      return correctedText;
      
    } catch (error) {
      console.error('‚ùå Error correcting OCR text:', error);
      return rawText;
    }
  }

  // Classify document content to detect inappropriate or junk files
  async classifyDocumentContent(text, filename = '') {
    try {
      console.log(`üîç Classifying document content...`);
      
      const prompt = `
B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i t√†i li·ªáu doanh nghi·ªáp. Ph√¢n t√≠ch vƒÉn b·∫£n v√† tr·∫£ l·ªùi:

TI√äU CH√ç CH·∫§P NH·∫¨N:
‚úÖ T√†i li·ªáu c√¥ng ty (quy ƒë·ªãnh, quy tr√¨nh, ch√≠nh s√°ch)
‚úÖ B√°o c√°o, bi√™n b·∫£n h·ªçp
‚úÖ H∆∞·ªõng d·∫´n, s∆° ƒë·ªì t·ªï ch·ª©c
‚úÖ H·ª£p ƒë·ªìng, th·ªèa thu·∫≠n
‚úÖ T√†i li·ªáu t√†i ch√≠nh, ki·ªÉm to√°n
‚úÖ VƒÉn b·∫£n ph√°p l√Ω li√™n quan c√¥ng ty

TI√äU CH√ç T·ª™ CH·ªêI:
‚ùå N·ªôi dung kh√¥ng li√™n quan c√¥ng ty
‚ùå T√†i li·ªáu c√° nh√¢n
‚ùå VƒÉn b·∫£n t·∫ßm b·∫≠y, spam
‚ùå N·ªôi dung nh·∫°y c·∫£m
‚ùå File r√°c, test, demo
‚ùå Qu·∫£ng c√°o, marketing kh√¥ng li√™n quan

FILENAME: ${filename}

CONTENT: ${text.substring(0, 2000)}...

Tr·∫£ l·ªùi CH√çNH X√ÅC theo format:
{
  "accept": true/false,
  "category": "Quy ƒë·ªãnh|Quy tr√¨nh|B√°o c√°o|H·ª£p ƒë·ªìng|T√†i ch√≠nh|Kh√°c",
  "confidence": 0.0-1.0,
  "reason": "L√Ω do ng·∫Øn g·ªçn",
  "businessRelevance": "M·ª©c ƒë·ªô li√™n quan c√¥ng ty 0.0-1.0"
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let classificationText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = classificationText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const classification = JSON.parse(jsonMatch[0]);
        console.log(`üìä Document classification:`, classification);
        return classification;
      }
      
      // Fallback classification
      return {
        accept: true,
        category: 'Kh√°c',
        confidence: 0.5,
        reason: 'Unable to classify automatically',
        businessRelevance: 0.5
      };
      
    } catch (error) {
      console.error('‚ùå Error classifying document:', error);
      // Default to accept if classification fails
      return {
        accept: true,
        category: 'Kh√°c',
        confidence: 0.3,
        reason: 'Classification error - defaulting to accept',
        businessRelevance: 0.3
      };
    }
  }

  // Check for duplicate documents using content similarity
  async checkForDuplicates(text, filename, companyId = null) {
    try {
      console.log(`üîç Checking for duplicate documents...`);
      
      // Get existing documents from the same company
      let existingDocs = [];
      if (companyId) {
        // Get all documents and filter by company_id
        const allDocs = await db.getDocuments();
        existingDocs = allDocs.filter(doc => doc.company_id === companyId);
      }
      
      if (existingDocs.length === 0) {
        return { isDuplicate: false, similarDocs: [] };
      }
      
      // Use AI to check similarity
      const prompt = `
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng t√†i li·ªáu. So s√°nh vƒÉn b·∫£n m·ªõi v·ªõi c√°c t√†i li·ªáu hi·ªán c√≥:

VƒÇN B·∫¢N M·ªöI:
Filename: ${filename}
Content: ${text.substring(0, 1500)}...

C√ÅC T√ÄI LI·ªÜU HI·ªÜN C√ì:
${existingDocs.slice(0, 5).map(doc => `
- ID: ${doc.id}
- Filename: ${doc.original_name}
- Content: ${doc.content_text ? doc.content_text.substring(0, 500) : 'No content'}...
`).join('\n')}

Ph√¢n t√≠ch v√† tr·∫£ l·ªùi theo format JSON:
{
  "isDuplicate": true/false,
  "similarDocs": [
    {
      "id": number,
      "filename": "string",
      "similarity": 0.0-1.0,
      "reason": "L√Ω do t∆∞∆°ng ƒë·ªìng"
    }
  ],
  "recommendation": "merge|replace|keep_separate",
  "confidenceScore": 0.0-1.0
}

L∆∞u √Ω:
- similarity > 0.8: Tr√πng l·∫∑p cao
- similarity > 0.6: C√≥ th·ªÉ merge
- similarity < 0.4: Kh√°c bi·ªát, gi·ªØ ri√™ng`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let analysisText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const analysis = JSON.parse(jsonMatch[0]);
        console.log(`üìä Duplicate analysis:`, analysis);
        return analysis;
      }
      
      return { isDuplicate: false, similarDocs: [] };
      
    } catch (error) {
      console.error('‚ùå Error checking duplicates:', error);
      return { isDuplicate: false, similarDocs: [] };
    }
  }

  // Merge similar documents using AI
  async mergeSimilarDocuments(newText, existingDoc, mergeReason) {
    try {
      console.log(`üîó Merging similar documents...`);
      
      const prompt = `
B·∫°n l√† chuy√™n gia merge t√†i li·ªáu. H√£y k·∫øt h·ª£p 2 t√†i li·ªáu sau th√†nh 1 t√†i li·ªáu ho√†n ch·ªânh:

L√ù DO MERGE: ${mergeReason}

T√ÄI LI·ªÜU HI·ªÜN C√ì:
${existingDoc.content_text}

T√ÄI LI·ªÜU M·ªöI:
${newText}

Y√äU C·∫¶U MERGE:
1. Gi·ªØ th√¥ng tin ƒë·∫ßy ƒë·ªß t·ª´ c·∫£ 2 t√†i li·ªáu
2. Lo·∫°i b·ªè th√¥ng tin tr√πng l·∫∑p
3. S·∫Øp x·∫øp theo logic (th·ªùi gian, m·ª©c ƒë·ªô quan tr·ªçng)
4. ƒê√°nh d·∫•u ngu·ªìn n·∫øu c√≥ th√¥ng tin xung ƒë·ªôt
5. Gi·ªØ format v√† c·∫•u tr√∫c r√µ r√†ng

T√ÄI LI·ªÜU ƒê√É MERGE:`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let mergedText = response.text().trim();
      
      // Clean up AI response
      if (mergedText.includes('T√ÄI LI·ªÜU ƒê√É MERGE:')) {
        mergedText = mergedText.split('T√ÄI LI·ªÜU ƒê√É MERGE:')[1].trim();
      }
      
      console.log(`‚úÖ Documents merged successfully: ${mergedText.length} characters`);
      return mergedText;
      
    } catch (error) {
      console.error('‚ùå Error merging documents:', error);
      return newText; // Return new text if merge fails
    }
  }

  // Analyze document structure and content for Q&A
  async analyzeDocumentStructure(text) {
    try {
      console.log(`üîç Analyzing document structure for Q&A...`);
      
      const prompt = `
Ph√¢n t√≠ch c·∫•u tr√∫c t√†i li·ªáu ƒë·ªÉ h·ªó tr·ª£ h·ªá th·ªëng h·ªèi ƒë√°p:

CONTENT: ${text.substring(0, 3000)}...

Tr·∫£ l·ªùi theo format JSON:
{
  "documentType": "Quy ƒë·ªãnh|Quy tr√¨nh|B√°o c√°o|H·ª£p ƒë·ªìng|S∆° ƒë·ªì|Kh√°c",
  "mainTopics": ["topic1", "topic2", "topic3"],
  "keyPoints": [
    {
      "section": "Ph·∫ßn n√†o",
      "content": "N·ªôi dung ch√≠nh",
      "importance": 1-5
    }
  ],
  "procedures": [
    {
      "step": 1,
      "description": "B∆∞·ªõc 1",
      "details": "Chi ti·∫øt"
    }
  ],
  "keyTerms": ["term1", "term2"],
  "canAnswerQuestions": [
    "C√≥ th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi g√¨?",
    "Quy tr√¨nh nh∆∞ th·∫ø n√†o?",
    "Ai l√† ng∆∞·ªùi ph·ª• tr√°ch?"
  ]
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let analysisText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const analysis = JSON.parse(jsonMatch[0]);
        console.log(`üìä Document structure analysis completed`);
        return analysis;
      }
      
      return {
        documentType: 'Kh√°c',
        mainTopics: [],
        keyPoints: [],
        procedures: [],
        keyTerms: [],
        canAnswerQuestions: []
      };
      
    } catch (error) {
      console.error('‚ùå Error analyzing document structure:', error);
      return {
        documentType: 'Kh√°c',
        mainTopics: [],
        keyPoints: [],
        procedures: [],
        keyTerms: [],
        canAnswerQuestions: []
      };
    }
  }

  // Process scanned PDF with Vision API
  async processScannedPDF(pdfPath, maxPages = 10) {
    try {
      console.log('üîç Processing scanned PDF with Vision API...');
      
      // Convert PDF to images
      const images = await this.convertPDFToImages(pdfPath, maxPages);
      
      if (images.length === 0) {
        throw new Error('No images extracted from PDF');
      }

      let allText = '';
      
      // Extract text from each image using Vision API
      for (const image of images) {
        const imagePath = image.path;
        const pageText = await this.extractTextFromImage(imagePath);
        
        if (pageText.trim()) {
          allText += `\n--- Trang ${images.indexOf(image) + 1} ---\n`;
          allText += pageText.trim() + '\n';
        }
        
        // Clean up image file
        if (fs.existsSync(imagePath)) {
          fs.unlinkSync(imagePath);
        }
      }

      console.log(`‚úÖ Vision API OCR completed. Extracted ${allText.length} characters`);
      
      // Apply AI-powered text correction
      if (allText.trim().length > 0) {
        const correctedText = await this.correctOCRText(allText);
        return correctedText;
      }
      
      return allText;

    } catch (error) {
      console.error('Error processing scanned PDF:', error);
      throw error;
    }
  }

  // Enhanced document processing with all new features
  async processDocumentWithEnhancements(pdfPath, filename, originalName, companyId = null) {
    try {
      console.log(`üöÄ Processing document with enhancements: ${originalName}`);
      
      // Step 1: Extract text (standard or OCR)
      const dataBuffer = fs.readFileSync(pdfPath);
      const pdfParse = require('pdf-parse');
      const data = await pdfParse(dataBuffer);
      let extractedText = data.text;
      
      // Use Vision API if standard extraction yields little text
      if (this.isScannedPDF(extractedText)) {
        console.log('üì∏ Using Vision API for scanned document...');
        extractedText = await this.processScannedPDF(pdfPath);
      }
      
      // Step 2: Classify content
      const classification = await this.classifyDocumentContent(extractedText, originalName);
      
      if (!classification.accept) {
        throw new Error(`Document rejected: ${classification.reason}`);
      }
      
      // Step 3: Check for duplicates
      const duplicateAnalysis = await this.checkForDuplicates(extractedText, originalName, companyId);
      
      // Step 4: Handle duplicates if found
      if (duplicateAnalysis.isDuplicate && duplicateAnalysis.recommendation === 'merge') {
        console.log('üîó Merging with similar document...');
        const similarDoc = duplicateAnalysis.similarDocs[0];
        const existingDoc = await db.getDocumentById(similarDoc.id);
        
        if (existingDoc) {
          extractedText = await this.mergeSimilarDocuments(
            extractedText, 
            existingDoc, 
            similarDoc.reason
          );
        }
      }
      
      // Step 5: Analyze document structure
      const structureAnalysis = await this.analyzeDocumentStructure(extractedText);
      
      return {
        text: extractedText,
        classification: classification,
        duplicateAnalysis: duplicateAnalysis,
        structureAnalysis: structureAnalysis,
        processingMethod: this.isScannedPDF(data.text) ? 'Vision API OCR' : 'Standard PDF'
      };
      
    } catch (error) {
      console.error('‚ùå Error in enhanced document processing:', error);
      throw error;
    }
  }

  // Clean up temporary files
  cleanup() {
    try {
      if (fs.existsSync(this.tempDir)) {
        const files = fs.readdirSync(this.tempDir);
        files.forEach(file => {
          fs.unlinkSync(path.join(this.tempDir, file));
        });
      }
    } catch (error) {
      console.error('Error cleaning up temp files:', error);
    }
  }
}

module.exports = new VisionOCRService(); 
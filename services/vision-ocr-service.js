const { ImageAnnotatorClient } = require('@google-cloud/vision');
const { convert } = require('pdf2pic');
const fs = require('fs');
const path = require('path');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { db: defaultDb } = require('../database');
require('dotenv').config();

class VisionOCRService {
  constructor() {
    this.tempDir = './temp-images';
    this.ensureTempDir();
    this.db = defaultDb; // Default database connection
    
    // Initialize Google Cloud Vision
    // Handle both local (keyFilename) and production (JSON credentials) environments
    let visionConfig = {
      projectId: process.env.GOOGLE_CLOUD_PROJECT_ID
    };

    if (process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON) {
      // Production: Parse JSON credentials from environment variable
      try {
        const credentials = JSON.parse(process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON);
        visionConfig.credentials = credentials;
        console.log('üîë Using JSON credentials for Google Cloud Vision');
      } catch (error) {
        console.error('‚ùå Failed to parse GOOGLE_APPLICATION_CREDENTIALS_JSON:', error);
        throw error;
      }
    } else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      // Local development: Use keyFilename
      visionConfig.keyFilename = process.env.GOOGLE_APPLICATION_CREDENTIALS;
      console.log('üîë Using keyFilename for Google Cloud Vision');
    } else {
      throw new Error('No Google Cloud credentials found. Set either GOOGLE_APPLICATION_CREDENTIALS_JSON or GOOGLE_APPLICATION_CREDENTIALS');
    }

    this.visionClient = new ImageAnnotatorClient(visionConfig);
    
    // Initialize Gemini AI for text correction and content analysis
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    this.model = this.genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }
  }

  // Set database connection
  setDbConnection(dbConnection) {
    try {
      // Ki·ªÉm tra xem dbConnection c√≥ h·ª£p l·ªá kh√¥ng
      if (!dbConnection) {
        console.error('‚ùå Invalid database connection provided to VisionOCRService');
        throw new Error('Invalid database connection');
      }

      // Ki·ªÉm tra c√°c ph∆∞∆°ng th·ª©c c·∫ßn thi·∫øt
      const requiredMethods = ['updateDocument', 'getDocuments', 'getDocumentById'];
      for (const method of requiredMethods) {
        if (typeof dbConnection[method] !== 'function') {
          console.error(`‚ùå Database connection missing required method: ${method}`);
          throw new Error(`Database connection missing required method: ${method}`);
        }
      }

      this.db = dbConnection;
      
      // Thi·∫øt l·∫≠p k·∫øt n·ªëi cho crossDocValidator n·∫øu ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
      if (this.crossDocValidator && typeof this.crossDocValidator.setDbConnection === 'function') {
        this.crossDocValidator.setDbConnection(dbConnection);
        console.log('‚úÖ Database connection set for Cross-Document Validator');
      }
      
      // Ki·ªÉm tra k·∫øt n·ªëi b·∫±ng c√°ch th·ª±c hi·ªán truy v·∫•n ƒë∆°n gi·∫£n
      this.testDatabaseConnection()
        .then(result => {
          if (result) {
            console.log('‚úÖ Database connection verified for VisionOCRService');
          }
        })
        .catch(err => {
          console.error('‚ùå Database connection test failed:', err);
        });
      
      return true;
    } catch (error) {
      console.error('‚ùå Error setting database connection:', error);
      throw error;
    }
  }

  // Test database connection
  async testDatabaseConnection() {
    try {
      if (!this.db) {
        return false;
      }
      
      // Ki·ªÉm tra xem c√≥ th·ªÉ truy c·∫≠p c√°c ph∆∞∆°ng th·ª©c c∆° b·∫£n kh√¥ng
      return typeof this.db.getDocuments === 'function' && 
             typeof this.db.updateDocument === 'function';
    } catch (error) {
      console.error('‚ùå Database connection test failed:', error);
      return false;
    }
  }

  ensureTempDir() {
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }
  }

  // Check if PDF is likely scanned (has very little text)
  isScannedPDF(extractedText) {
    if (!extractedText || extractedText.trim().length < 100) {
      return true;
    }
    
    // Check if text is mostly whitespace or special characters
    const meaningfulText = extractedText.replace(/\s+/g, '').replace(/[^a-zA-Z√Ä-·ªπ0-9]/g, '');
    return meaningfulText.length < 50;
  }

  // Convert PDF to images with high quality settings
  async convertPDFToImages(pdfPath, maxPages = null) {
    // Use environment variable or default to 100 pages (was 10)
    const pageLimit = maxPages || parseInt(process.env.MAX_PDF_PAGES) || 100;
    try {
      const options = {
        density: 300,           // High DPI for Vision API
        saveFilename: "page",
        savePath: this.tempDir,
        format: "png",
        quality: 100,
        width: 2000,           // Good resolution for Vision API
        graphicsmagick: true
      };

      console.log(`üì∑ Converting PDF to images for Vision API (limit: ${pageLimit} pages)...`);
      
      const convert = require('pdf2pic').fromPath(pdfPath, options);
      const results = [];
      let actualPages = 0;
      
      for (let i = 1; i <= pageLimit; i++) {
        try {
          const result = await convert(i, { responseType: "image" });
          
          if (result && result.path) {
            results.push(result);
            actualPages = i;
            console.log(`‚úÖ Converted page ${i}: ${result.path}`);
          } else {
            console.log(`üìÑ Reached end of PDF at page ${i-1}`);
            break;
          }
        } catch (error) {
          console.log(`‚ùå Error converting page ${i}:`, error.message);
          if (i === 1) {
            // Try bulk conversion
            try {
              console.log(`üîÑ Trying bulk conversion for all pages...`);
              const bulkResults = await convert.bulk(-1, { responseType: "image" });
              const limitedResults = bulkResults.slice(0, pageLimit);
              
              if (bulkResults.length > pageLimit) {
                console.log(`‚ö†Ô∏è  PDF has ${bulkResults.length} pages, processing only first ${pageLimit} pages`);
                console.log(`üí° To process more pages, set MAX_PDF_PAGES environment variable`);
              }
              
              console.log(`‚úÖ Bulk converted ${limitedResults.length} pages`);
              return limitedResults;
            } catch (bulkError) {
              console.log(`‚ùå Bulk conversion failed:`, bulkError.message);
            }
          }
          break;
        }
      }

      // Log conversion summary
      console.log(`üìä PDF conversion completed: ${results.length} pages processed`);
      if (actualPages === pageLimit) {
        console.log(`‚ö†Ô∏è  Reached page limit (${pageLimit}). PDF might have more pages.`);
        console.log(`üí° To process more pages, set MAX_PDF_PAGES environment variable to higher value`);
      }

      return results;
    } catch (error) {
      console.error('Error converting PDF to images:', error);
      throw error;
    }
  }

  // Extract text from image using Google Cloud Vision
  async extractTextFromImage(imagePath) {
    try {
      console.log(`üîç Extracting text from image using Vision API: ${imagePath}`);
      
      const [result] = await this.visionClient.textDetection(imagePath);
      const detections = result.textAnnotations;
      
      if (!detections || detections.length === 0) {
        console.log('No text detected in image');
        return '';
      }
      
      // First detection contains the full text
      const fullText = detections[0].description;
      
      console.log(`‚úÖ Vision API extracted ${fullText.length} characters`);
      return fullText;
      
    } catch (error) {
      console.error('Error in Vision API OCR:', error);
      return '';
    }
  }

  // Correct OCR text using AI with enhanced Vietnamese support
  async correctOCRText(rawText) {
    try {
      if (!rawText || rawText.trim().length < 10) {
        return rawText;
      }

      console.log(`üîß Correcting OCR text (${rawText.length} characters) with AI...`);
      
      const prompt = `
B·∫°n l√† chuy√™n gia s·ª≠a ch√≠nh t·∫£ v√† c·∫£i thi·ªán vƒÉn b·∫£n ti·∫øng Vi·ªát t·ª´ OCR. Nhi·ªám v·ª•:

NGUY√äN T·∫ÆC:
1. CH·ªà s·ª≠a l·ªói ch√≠nh t·∫£, d·∫•u thanh v√† nh·∫≠n d·∫°ng sai
2. KH√îNG thay ƒë·ªïi n·ªôi dung, √Ω nghƒ©a ho·∫∑c c·∫•u tr√∫c
3. Gi·ªØ nguy√™n format, s·ªë li·ªáu, ng√†y th√°ng
4. S·ª≠a t√™n c√¥ng ty, ch·ª©c v·ª• n·∫øu b·ªã sai
5. C·∫£i thi·ªán kh·∫£ nƒÉng ƒë·ªçc nh∆∞ng gi·ªØ nguy√™n th√¥ng tin

C√ÅC L·ªñI TH∆Ø·ªúNG G·∫∂P:
- D·∫•u thanh ti·∫øng Vi·ªát: "nhan su" ‚Üí "nh√¢n s·ª±"
- Ch·ªØ hoa/th∆∞·ªùng: "CONG TY" ‚Üí "C√îNG TY"
- K√Ω t·ª± ƒë·∫∑c bi·ªát: "¬ß" ‚Üí "ƒêi·ªÅu", "¬¢" ‚Üí "Ch∆∞∆°ng"
- T√™n c√¥ng ty: "PHAT DAT" ‚Üí "PH√ÅT ƒê·∫†T"
- Ch·ª©c v·ª•: "GIAM DOC" ‚Üí "GI√ÅM ƒê·ªêC"

VƒÇN B·∫¢N C·∫¶N S·ª¨A:
${rawText}

VƒÇN B·∫¢N ƒê√É S·ª¨A:`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let correctedText = response.text().trim();
      
      // Clean up AI response
      if (correctedText.includes('VƒÇN B·∫¢N ƒê√É S·ª¨A:')) {
        correctedText = correctedText.split('VƒÇN B·∫¢N ƒê√É S·ª¨A:')[1].trim();
      }
      
      // Safety check
      if (!correctedText || correctedText.length < rawText.length * 0.3) {
        console.log('‚ö†Ô∏è Correction result too short, using original text');
        return rawText;
      }
      
      console.log(`‚úÖ Text correction completed: ${rawText.length} ‚Üí ${correctedText.length} chars`);
      return correctedText;
      
    } catch (error) {
      console.error('‚ùå Error correcting OCR text:', error);
      return rawText;
    }
  }

  // Classify document content to detect inappropriate or junk files
  async classifyDocumentContent(text, filename = '') {
    try {
      console.log(`üîç Classifying document content...`);
      
      const prompt = `
B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i t√†i li·ªáu doanh nghi·ªáp. Ph√¢n t√≠ch vƒÉn b·∫£n v√† tr·∫£ l·ªùi:

TI√äU CH√ç CH·∫§P NH·∫¨N:
‚úÖ T√†i li·ªáu c√¥ng ty (quy ƒë·ªãnh, quy tr√¨nh, ch√≠nh s√°ch)
‚úÖ B√°o c√°o, bi√™n b·∫£n h·ªçp
‚úÖ H∆∞·ªõng d·∫´n, s∆° ƒë·ªì t·ªï ch·ª©c
‚úÖ H·ª£p ƒë·ªìng, th·ªèa thu·∫≠n
‚úÖ T√†i li·ªáu t√†i ch√≠nh, ki·ªÉm to√°n
‚úÖ VƒÉn b·∫£n ph√°p l√Ω li√™n quan c√¥ng ty

TI√äU CH√ç T·ª™ CH·ªêI:
‚ùå N·ªôi dung kh√¥ng li√™n quan c√¥ng ty
‚ùå T√†i li·ªáu c√° nh√¢n
‚ùå VƒÉn b·∫£n t·∫ßm b·∫≠y, spam
‚ùå N·ªôi dung nh·∫°y c·∫£m
‚ùå File r√°c, test, demo
‚ùå Qu·∫£ng c√°o, marketing kh√¥ng li√™n quan

FILENAME: ${filename}

CONTENT: ${text.substring(0, 2000)}...

Tr·∫£ l·ªùi CH√çNH X√ÅC theo format:
{
  "accept": true/false,
  "category": "Quy ƒë·ªãnh|Quy tr√¨nh|B√°o c√°o|H·ª£p ƒë·ªìng|T√†i ch√≠nh|Kh√°c",
  "confidence": 0.0-1.0,
  "reason": "L√Ω do ng·∫Øn g·ªçn",
  "businessRelevance": "M·ª©c ƒë·ªô li√™n quan c√¥ng ty 0.0-1.0"
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      let classificationText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = classificationText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const classification = JSON.parse(jsonMatch[0]);
        console.log(`üìä Document classification:`, classification);
        return classification;
      }
      
      // Fallback classification
      return {
        accept: true,
        category: 'Kh√°c',
        confidence: 0.5,
        reason: 'Unable to classify automatically',
        businessRelevance: 0.5
      };
      
    } catch (error) {
      console.error('‚ùå Error classifying document:', error);
      // Default to accept if classification fails
      return {
        accept: true,
        category: 'Kh√°c',
        confidence: 0.3,
        reason: 'Classification error - defaulting to accept',
        businessRelevance: 0.3
      };
    }
  }

  // Check for duplicate documents using content similarity
  async checkForDuplicates(text, filename, companyId = null) {
    try {
      console.log(`üîç Checking for duplicate documents...`);
      
      // Get existing documents from the same company
      let existingDocs = [];
      if (companyId) {
        // Get all documents and filter by company_id
        const allDocs = await this.db.getDocuments();
        existingDocs = allDocs.filter(doc => doc.company_id === companyId);
      }
      
      if (existingDocs.length === 0) {
        return { isDuplicate: false, similarDocs: [] };
      }
      
      // ƒê·∫ßu ti√™n so s√°nh t√™n file ƒë·ªÉ ngƒÉn ch·∫∑n merge c√°c file kh√°c lo·∫°i
      const filenameParts = originalName.toLowerCase().split(/[\s\-\.\_]+/);
      
      // C√°c t·ª´ kh√≥a ƒë·ªÉ so s√°nh t√™n file
      const significantKeywords = filenameParts.filter(part => part.length > 3);
      
      // L·ªçc ra c√°c t√†i li·ªáu kh√¥ng thu·ªôc ph√≤ng ban kh√°c nhau
      let filteredDocs = [];
      for (const doc of existingDocs) {
        // Ki·ªÉm tra n·∫øu t√†i li·ªáu thu·ªôc ph√≤ng ban kh√°c nhau
        if (this.filesReferToDifferentEntities(originalName, doc.original_name)) {
          console.log(`üö´ Files appear to refer to different departments/entities: "${originalName}" vs "${doc.original_name}"`);
          continue; // Skip this document from consideration for merging
        }
        filteredDocs.push(doc);
      }
      
      // N·∫øu kh√¥ng c√≤n t√†i li·ªáu n√†o sau khi l·ªçc, kh√¥ng c√≥ tr√πng l·∫∑p
      if (filteredDocs.length === 0) {
        console.log(`‚úÖ No similar documents found after filtering by department`);
        return { isDuplicate: false, similarDocs: [] };
      }
      
      // Now run the AI-based duplicate check with filtered documents
      const duplicateAnalysis = await this.checkForDuplicates(text, originalName, companyId);
      
      // Additional check: Override recommendation if we detect critical differences in filename
      if (duplicateAnalysis.similarDocs && duplicateAnalysis.similarDocs.length > 0) {
        const filteredSimilarDocs = [];
        
        for (const similarDoc of duplicateAnalysis.similarDocs) {
          const existingDoc = await this.db.getDocumentById(similarDoc.id);
          if (existingDoc && this.filesReferToDifferentEntities(originalName, existingDoc.original_name)) {
            console.log(`üîí Excluding document from merge due to different entities in filenames: ${existingDoc.original_name}`);
            // Skip this document
          } else {
            filteredSimilarDocs.push(similarDoc);
          }
        }
        
        // Update the similarDocs array with filtered results
        duplicateAnalysis.similarDocs = filteredSimilarDocs;
        
        // If no similar docs left after filtering, set isDuplicate to false
        if (filteredSimilarDocs.length === 0) {
          duplicateAnalysis.isDuplicate = false;
          duplicateAnalysis.recommendation = 'keep_separate';
          console.log(`‚úÖ No similar documents left after department filtering`);
        }
      }
      
      return duplicateAnalysis;
    } catch (error) {
      console.error('‚ùå Error in enhanced duplicate check:', error);
      return { isDuplicate: false, similarDocs: [], recommendation: 'keep_separate' };
    }
  }
  
  // Helper to check if filenames refer to different departments/entities
  filesReferToDifferentEntities(filename1, filename2) {
    if (!filename1 || !filename2) return false;
    
    const normalize = (text) => text.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "");
    
    const name1 = normalize(filename1);
    const name2 = normalize(filename2);
    
    // Danh s√°ch ph√≤ng ban, b·ªô ph·∫≠n th∆∞·ªùng g·∫∑p
    const departments = {
      "phap_che": ["phap che", "ban phap che", "phong phap che", "bo phan phap che", "ph√°p ch·∫ø", "phapche", "pc"],
      "tai_chinh": ["tai chinh", "ban tai chinh", "phong tai chinh", "bo phan tai chinh", "t√†i ch√≠nh", "taichinh", "tc", "kt-qt", "kt"],
      "ke_toan": ["ke toan", "ban ke toan", "phong ke toan", "bo phan ke toan", "k·∫ø to√°n", "ketoan", "kt"],
      "nhan_su": ["nhan su", "ban nhan su", "phong nhan su", "bo phan nhan su", "nh√¢n s·ª±", "nhansu", "ns"],
      "it": ["it", "cntt", "cong nghe thong tin", "ban cntt", "c√¥ng ngh·ªá th√¥ng tin", "th√¥ng tin"],
      "san_xuat": ["san xuat", "ban san xuat", "phong san xuat", "b·ªô ph·∫≠n s·∫£n xu·∫•t", "s·∫£n xu·∫•t", "sx"],
      "kinh_doanh": ["kinh doanh", "ban kinh doanh", "phong kinh doanh", "b·ªô ph·∫≠n kinh doanh", "kd"]
    };
    
    const dept1 = this.extractDepartment(filename1);
    const dept2 = this.extractDepartment(filename2);
    
    console.log(`üìä Extracted departments: "${dept1}" vs "${dept2}" from "${filename1}" vs "${filename2}"`);
    
    // If both have departments detected and they're different
    if (dept1 && dept2 && dept1 !== dept2) {
      console.log(`üîé Found different departments: "${dept1}" vs "${dept2}"`);
      return true;
    }
    
    return false;
  }
  
  // Extract department from filename
  extractDepartment(filename) {
    if (!filename) return null;
    
    const normalize = (text) => text.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "");
    const normalizedName = normalize(filename);
    
    // Danh s√°ch ph√≤ng ban, b·ªô ph·∫≠n th∆∞·ªùng g·∫∑p
    const departments = {
      "phap_che": ["phap che", "ban phap che", "phong phap che", "bo phan phap che", "ph√°p ch·∫ø", "phapche", "pc"],
      "tai_chinh": ["tai chinh", "ban tai chinh", "phong tai chinh", "bo phan tai chinh", "t√†i ch√≠nh", "taichinh", "tc", "kt-qt", "kt"],
      "ke_toan": ["ke toan", "ban ke toan", "phong ke toan", "bo phan ke toan", "k·∫ø to√°n", "ketoan", "kt"],
      "nhan_su": ["nhan su", "ban nhan su", "phong nhan su", "bo phan nhan su", "nh√¢n s·ª±", "nhansu", "ns"],
      "it": ["it", "cntt", "cong nghe thong tin", "ban cntt", "c√¥ng ngh·ªá th√¥ng tin", "th√¥ng tin"],
      "san_xuat": ["san xuat", "ban san xuat", "phong san xuat", "b·ªô ph·∫≠n s·∫£n xu·∫•t", "s·∫£n xu·∫•t", "sx"],
      "kinh_doanh": ["kinh doanh", "ban kinh doanh", "phong kinh doanh", "b·ªô ph·∫≠n kinh doanh", "kd"]
    };
    
    // Ki·ªÉm tra m√£ ph√≤ng ban trong t√™n file (th∆∞·ªùng l√† 2-3 k√Ω t·ª± sau m√£ c√¥ng ty)
    // V√≠ d·ª•: PDH-PC-xxx (Ph√°p ch·∫ø), PDH-TC-xxx (T√†i ch√≠nh), PDH-KT-xxx (K·∫ø to√°n)
    const deptCodeMatch = normalizedName.match(/pdh[-_]([a-z]{2,3})[-_]/i);
    if (deptCodeMatch) {
      const deptCode = deptCodeMatch[1].toLowerCase();
      if (deptCode === 'pc') return 'phap_che';
      if (deptCode === 'tc') return 'tai_chinh';
      if (deptCode === 'kt') return 'ke_toan';
      if (deptCode === 'ns') return 'nhan_su';
      if (deptCode === 'it' || deptCode === 'cn') return 'it';
      if (deptCode === 'sx') return 'san_xuat';
      if (deptCode === 'kd') return 'kinh_doanh';
    }
    
    // Ki·ªÉm tra t√™n ph√≤ng ban ƒë·∫ßy ƒë·ªß trong t√™n file
    for (const [deptKey, variants] of Object.entries(departments)) {
      for (const variant of variants) {
        if (normalizedName.includes(variant)) {
          return deptKey;
        }
      }
    }
    
    return null;
  }
  
  // Generate structure analysis from filename when OCR fails
  async generateStructureFromFilename(filename) {
    try {
      const filenameWithoutExtension = filename.replace(/\.[^/.]+$/, "");
      
      const prompt = `
Ph√¢n t√≠ch t√™n file n√†y v√† t·∫°o metadata c·∫•u tr√∫c vƒÉn b·∫£n gi·∫£ ƒë·ªãnh ph√π h·ª£p:

FILENAME: ${filenameWithoutExtension}

Tr·∫£ l·ªùi theo format JSON:
{
  "documentType": "Quy ƒë·ªãnh|Quy tr√¨nh|B√°o c√°o|H·ª£p ƒë·ªìng|S∆° ƒë·ªì|Kh√°c",
  "mainTopics": ["topic1", "topic2"],
  "keyPoints": [
    {
      "section": "Ph·∫ßn n√†o",
      "content": "N·ªôi dung gi·∫£ ƒë·ªãnh ph√π h·ª£p",
      "importance": 1-5
    }
  ],
  "procedures": [],
  "keyTerms": ["term1", "term2"],
  "canAnswerQuestions": [
    "C√¢u h·ªèi li√™n quan ƒë·∫øn file n√†y",
    "N·ªôi dung g√¨ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong file n√†y?"
  ]
}`;

      const result = await this.model.generateContent(prompt);
      const response = await result.response;
      const analysisText = response.text().trim();
      
      // Extract JSON from response
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const analysis = JSON.parse(jsonMatch[0]);
        console.log(`üìä Generated structure from filename`);
        return analysis;
      }
      
      // Fallback structure
      return {
        documentType: this.detectDocumentTypeFromFilename(filename),
        mainTopics: [filenameWithoutExtension],
        keyPoints: [{
          section: "To√†n t√†i li·ªáu",
          content: `N·ªôi dung li√™n quan ƒë·∫øn ${filenameWithoutExtension}`,
          importance: 3
        }],
        procedures: [],
        keyTerms: this.extractKeyTermsFromFilename(filename),
        canAnswerQuestions: this.generateDefaultQuestions(filename)
      };
      
    } catch (error) {
      console.error('‚ùå Error generating structure from filename:', error);
      return {
        documentType: 'Kh√°c',
        mainTopics: [],
        keyPoints: [],
        procedures: [],
        keyTerms: [],
        canAnswerQuestions: []
      };
    }
  }
  
  // Extract key terms from filename
  extractKeyTermsFromFilename(filename) {
    const filenameWithoutExtension = filename.replace(/\.[^/.]+$/, "");
    const terms = [];
    
    // Extract company name if present
    if (filenameWithoutExtension.includes('PDH')) {
      terms.push('PDH', 'Ph√°t ƒê·∫°t');
    }
    
    // Extract common document types
    if (/so do|s∆° ƒë·ªì/i.test(filenameWithoutExtension)) {
      terms.push('S∆° ƒë·ªì', 'C∆° c·∫•u t·ªï ch·ª©c');
    }
    
    if (/quy trinh|quy tr√¨nh/i.test(filenameWithoutExtension)) {
      terms.push('Quy tr√¨nh');
    }
    
    if (/quy dinh|quy ƒë·ªãnh/i.test(filenameWithoutExtension)) {
      terms.push('Quy ƒë·ªãnh');
    }
    
    // Extract department names
    if (/phap che|ph√°p ch·∫ø/i.test(filenameWithoutExtension)) {
      terms.push('Ban Ph√°p ch·∫ø', 'Ph√°p ch·∫ø');
    }
    
    if (/tai chinh|t√†i ch√≠nh/i.test(filenameWithoutExtension)) {
      terms.push('Ban T√†i ch√≠nh', 'T√†i ch√≠nh');
    }
    
    if (/ke toan|k·∫ø to√°n/i.test(filenameWithoutExtension)) {
      terms.push('Ban K·∫ø to√°n', 'K·∫ø to√°n');
    }
    
    if (/nhan su|nh√¢n s·ª±/i.test(filenameWithoutExtension)) {
      terms.push('Ban Nh√¢n s·ª±', 'Nh√¢n s·ª±');
    }
    
    // Add the filename itself as a term if not too long
    if (filenameWithoutExtension.length < 50) {
      terms.push(filenameWithoutExtension);
    }
    
    return [...new Set(terms)]; // Remove duplicates
  }
  
  // Detect document type from filename
  detectDocumentTypeFromFilename(filename) {
    const filenameLower = filename.toLowerCase();
    
    // Ki·ªÉm tra d·∫°ng file
    if (/so do|s∆° ƒë·ªì/i.test(filenameLower)) {
      return 'S∆° ƒë·ªì';
    }
    
    if (/quy[ -]?trinh|quy[ -]?tr√¨nh|trinh tu|tr√¨nh t·ª±/i.test(filenameLower)) {
      return 'Quy tr√¨nh';
    }
    
    if (/quy[ -]?dinh|quy[ -]?ƒë·ªãnh|dinh muc|ƒë·ªãnh m·ª©c/i.test(filenameLower)) {
      return 'Quy ƒë·ªãnh';
    }
    
    if (/bao cao|b√°o c√°o/i.test(filenameLower)) {
      return 'B√°o c√°o';
    }
    
    if (/hop dong|h·ª£p ƒë·ªìng|contract/i.test(filenameLower)) {
      return 'H·ª£p ƒë·ªìng';
    }
    
    // Ph√°t hi·ªán theo ƒë·ªãnh d·∫°ng c·ªßa t√™n file
    if (filenameLower.startsWith('quy-trinh') || filenameLower.includes('-qt-')) {
      return 'Quy tr√¨nh';
    }
    
    if (filenameLower.startsWith('quy-dinh') || filenameLower.includes('-qd-')) {
      return 'Quy ƒë·ªãnh';
    }
    
    // Ph√°t hi·ªán c√°c t·ª´ kh√≥a kh√°c li√™n quan ƒë·∫øn quy tr√¨nh
    if (filenameLower.includes('vay-von') || 
        filenameLower.includes('vay von') || 
        filenameLower.includes('thu tuc') ||
        filenameLower.includes('th·ªß t·ª•c')) {
      return 'Quy tr√¨nh';
    }
    
    return 'Kh√°c';
  }
  
  // Generate default questions for a document based on filename
  generateDefaultQuestions(filename, category = null) {
    const questions = [];
    const filenameLower = filename.toLowerCase();
    const documentType = category || this.detectDocumentTypeFromFilename(filename);
    
    // Common questions for all document types
    questions.push(`T√†i li·ªáu "${filename}" c√≥ n·ªôi dung g√¨?`);
    questions.push(`ƒê√¢y l√† lo·∫°i t√†i li·ªáu g√¨?`);
    
    // Questions specific to document type
    if (documentType === 'S∆° ƒë·ªì') {
      questions.push(`S∆° ƒë·ªì n√†y m√¥ t·∫£ c·∫•u tr√∫c n√†o?`);
      
      if (/phap che|ph√°p ch·∫ø/i.test(filenameLower)) {
        questions.push(`Ban Ph√°p ch·∫ø c√≥ nh·ªØng v·ªã tr√≠ n√†o?`);
        questions.push(`C∆° c·∫•u t·ªï ch·ª©c c·ªßa Ban Ph√°p ch·∫ø nh∆∞ th·∫ø n√†o?`);
        questions.push(`Ai l√† tr∆∞·ªüng Ban Ph√°p ch·∫ø?`);
      }
      
      if (/tai chinh|t√†i ch√≠nh/i.test(filenameLower)) {
        questions.push(`Ban T√†i ch√≠nh c√≥ nh·ªØng v·ªã tr√≠ n√†o?`);
        questions.push(`C∆° c·∫•u t·ªï ch·ª©c c·ªßa Ban T√†i ch√≠nh nh∆∞ th·∫ø n√†o?`);
        questions.push(`Ai l√† tr∆∞·ªüng Ban T√†i ch√≠nh?`);
      }
    }
    
    if (documentType === 'Quy tr√¨nh') {
      questions.push(`Quy tr√¨nh n√†y c√≥ nh·ªØng b∆∞·ªõc n√†o?`);
      questions.push(`Ai ch·ªãu tr√°ch nhi·ªám trong quy tr√¨nh n√†y?`);
    }
    
    if (documentType === 'Quy ƒë·ªãnh') {
      questions.push(`Quy ƒë·ªãnh n√†y √°p d·ª•ng cho ƒë·ªëi t∆∞·ª£ng n√†o?`);
      questions.push(`C√≥ nh·ªØng ƒëi·ªÅu kho·∫£n quan tr·ªçng n√†o trong quy ƒë·ªãnh n√†y?`);
    }
    
    // Limit to 10 questions
    return questions.slice(0, 10);
  }

  // Cross-document validation and OCR correction - called after document is saved
  async performCrossDocumentValidation(documentId, text, filename, companyId) {
    try {
      // Ki·ªÉm tra k·∫øt n·ªëi database tr∆∞·ªõc khi th·ª±c hi·ªán
      if (!this.db || typeof this.db.query !== 'function') {
        console.error('‚ùå No valid database connection for cross-document validation');
        throw new Error('Database connection not available or invalid');
      }

      // Kh·ªüi t·∫°o cross-document validation service n·∫øu ch∆∞a c√≥
      if (!this.crossDocValidator) {
        const CrossDocumentValidationService = require('../src/services/validation/crossDocumentValidationService');
        this.crossDocValidator = new CrossDocumentValidationService();
        // Pass the database connection to the validator
        if (this.db) {
          this.crossDocValidator.setDbConnection(this.db);
        }
      }
      
      // Ki·ªÉm tra l·∫°i k·∫øt n·ªëi database trong validator
      if (!this.crossDocValidator.db || typeof this.crossDocValidator.db.query !== 'function') {
        console.error('‚ùå Cross-document validator has no valid database connection');
        throw new Error('Cross-document validator database connection not available');
      }
      
      // Perform cross-document validation and correction
      const validationResult = await this.crossDocValidator.validateAndCorrectDocument(
        documentId, 
        text, 
        filename, 
        companyId
      );
      
      // Update document with corrected text if significant corrections were made
      if (validationResult.corrections && validationResult.corrections.length > 0 && 
          validationResult.confidence > 0.8 && 
          validationResult.correctedText !== validationResult.originalText) {
        
        console.log(`‚úÖ Applying ${validationResult.corrections.length} corrections to document ${documentId}`);
        
        // Update document content with corrected text
        await this.db.updateDocument(documentId, {
          content_text: validationResult.correctedText,
          processing_notes: JSON.stringify({
            ocr_corrections: validationResult.corrections.length,
            entity_conflicts: validationResult.conflicts ? validationResult.conflicts.length : 0,
            validation_confidence: validationResult.confidence,
            processing_timestamp: new Date().toISOString()
          })
        });
        
        console.log(`üìù Updated document ${documentId} with corrected text and metadata`);
      }
      
      // Log validation results
      await this.logValidationResults(documentId, validationResult);
      
      return validationResult;
      
    } catch (error) {
      console.error('‚ùå Error in cross-document validation:', error);
      // Tr·∫£ v·ªÅ l·ªói r√µ r√†ng ƒë·ªÉ controller c√≥ th·ªÉ x·ª≠ l√Ω
      return {
        originalText: text,
        correctedText: text,
        entities: {},
        corrections: [],
        conflicts: [],
        confidence: 0.5,
        error: error.message,
        errorType: 'validation_error',
        success: false
      };
    }
  }

  // Log validation results for debugging and auditing
  async logValidationResults(documentId, validationResult) {
    try {
      // Ki·ªÉm tra k·∫øt n·ªëi database
      if (!this.db || typeof this.db.query !== 'function') {
        console.error('‚ùå Cannot log validation results: No valid database connection');
        return;
      }

      // Create tables if they don't exist
      await this.ensureValidationTablesExist();
      
      await this.db.query(`
        INSERT INTO validation_logs (
          document_id, 
          validation_type, 
          original_text, 
          corrected_text, 
          entities_found, 
          corrections_applied, 
          conflicts_resolved, 
          confidence_score,
          processing_time_ms
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
      `, [
        documentId,
        'cross_document_validation',
        validationResult.originalText ? validationResult.originalText.substring(0, 1000) : '',
        validationResult.correctedText ? validationResult.correctedText.substring(0, 1000) : '',
        JSON.stringify(validationResult.entities || {}),
        JSON.stringify(validationResult.corrections || []),
        JSON.stringify(validationResult.conflicts || []),
        validationResult.confidence || 0.0,
        0 // We'll add timing later if needed
      ]);
      
      console.log(`üìä Logged validation results for document ${documentId}`);
    } catch (error) {
      console.error('‚ùå Error logging validation results:', error);
    }
  }

  // Ensure validation tables exist (for first run)
  async ensureValidationTablesExist() {
    try {
      // Ki·ªÉm tra k·∫øt n·ªëi database
      if (!this.db || typeof this.db.query !== 'function') {
        console.error('‚ùå Cannot ensure validation tables: No valid database connection');
        return;
      }

      const checkTablesQuery = `
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name IN ('document_metadata', 'company_metadata', 'validation_logs', 'entity_references')
      `;
      
      const result = await this.db.query(checkTablesQuery);
      
      if (!result.rows || result.rows.length < 4) {
        console.log('üì¶ Creating validation tables...');
        // Read and execute schema
        const schemaPath = path.join(__dirname, '../scripts/create-metadata-tables.sql');
        if (fs.existsSync(schemaPath)) {
          const schema = fs.readFileSync(schemaPath, 'utf8');
          await this.db.query(schema);
          console.log('‚úÖ Validation tables created successfully');
        } else {
          console.log('‚ö†Ô∏è Schema file not found at:', schemaPath);
          // Create tables inline as fallback
          await this.createValidationTablesInline();
        }
      }
    } catch (error) {
      console.error('‚ùå Error ensuring validation tables exist:', error);
    }
  }
  
  // Create validation tables inline if SQL file is not found
  async createValidationTablesInline() {
    try {
      const createTablesSQL = `
        -- Document metadata table
        CREATE TABLE IF NOT EXISTS document_metadata (
          id SERIAL PRIMARY KEY,
          document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
          entities JSONB DEFAULT '{}',
          created_at TIMESTAMP DEFAULT NOW(),
          updated_at TIMESTAMP DEFAULT NOW(),
          UNIQUE(document_id)
        );

        -- Company metadata table
        CREATE TABLE IF NOT EXISTS company_metadata (
          id SERIAL PRIMARY KEY,
          company_id INTEGER REFERENCES companies(id) ON DELETE CASCADE,
          metadata JSONB DEFAULT '{}',
          created_at TIMESTAMP DEFAULT NOW(),
          updated_at TIMESTAMP DEFAULT NOW(),
          UNIQUE(company_id)
        );

        -- Validation logs table
        CREATE TABLE IF NOT EXISTS validation_logs (
          id SERIAL PRIMARY KEY,
          document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
          validation_type VARCHAR(100) NOT NULL,
          original_text TEXT,
          corrected_text TEXT,
          entities_found JSONB DEFAULT '{}',
          corrections_applied JSONB DEFAULT '[]',
          conflicts_resolved JSONB DEFAULT '[]',
          confidence_score DECIMAL(3,2) DEFAULT 0.0,
          processing_time_ms INTEGER DEFAULT 0,
          created_at TIMESTAMP DEFAULT NOW()
        );

        -- Entity references table for fast lookup
        CREATE TABLE IF NOT EXISTS entity_references (
          id SERIAL PRIMARY KEY,
          entity_name VARCHAR(255) NOT NULL,
          entity_type VARCHAR(50) NOT NULL,
          document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
          company_id INTEGER REFERENCES companies(id) ON DELETE CASCADE,
          confidence DECIMAL(3,2) DEFAULT 1.0,
          created_at TIMESTAMP DEFAULT NOW()
        );
      `;
      
      // Split and execute each statement
      const statements = createTablesSQL.split(';')
        .map(stmt => stmt.trim())
        .filter(stmt => stmt.length > 0);
      
      for (const statement of statements) {
        await this.db.query(statement);
      }
      
      console.log('‚úÖ Validation tables created successfully (inline SQL)');
    } catch (error) {
      console.error('‚ùå Error creating validation tables inline:', error);
    }
  }

  // Clean up temporary files
  cleanup() {
    try {
      if (fs.existsSync(this.tempDir)) {
        const files = fs.readdirSync(this.tempDir);
        files.forEach(file => {
          fs.unlinkSync(path.join(this.tempDir, file));
        });
      }
    } catch (error) {
      console.error('Error cleaning up temp files:', error);
    }
  }

  // Enhanced document processing (main function)
  async processDocumentWithEnhancements(pdfPath, filename, originalName, companyId = null) {
    try {
      console.log(`üöÄ Processing document with enhancements: ${originalName}`);
      // Step 1: Extract text (use standard PDF extraction + OCR if needed)
      const dataBuffer = fs.readFileSync(pdfPath);
      const pdfParse = require('pdf-parse');
      const data = await pdfParse(dataBuffer);
      let extractedText = data.text;
      // Use OCR if standard extraction yields little text
      if (this.isScannedPDF(extractedText)) {
        console.log('üì∏ Using Vision API for scanned document...');
        // Convert PDF to images and extract text from each page
        const images = await this.convertPDFToImages(pdfPath);
        let ocrText = '';
        for (const img of images) {
          ocrText += await this.extractTextFromImage(img.path) + '\n';
        }
        extractedText = ocrText;
      }
      // Apply text correction
      extractedText = await this.correctOCRText(extractedText);
      // Step 2: Classify content
      const classification = await this.classifyDocumentContent(extractedText, originalName);
      if (!classification.accept) {
        throw new Error(`Document rejected: ${classification.reason}`);
      }
      // Step 3: Check for duplicates
      const duplicateAnalysis = await this.checkForDuplicates(extractedText, originalName, companyId);
      // Step 4: Handle duplicates if found
      if (duplicateAnalysis.isDuplicate && duplicateAnalysis.recommendation === 'merge') {
        console.log('üîó Would merge with similar document...');
        const similarDoc = duplicateAnalysis.similarDocs[0];
        if (similarDoc) {
          const existingDoc = await this.db.getDocumentById(similarDoc.id);
          if (existingDoc) {
            extractedText = await this.mergeSimilarDocuments(
              extractedText,
              existingDoc,
              similarDoc.reason
            );
          }
        }
      }
      // Step 5: Analyze document structure
      const structureAnalysis = await this.generateStructureFromFilename(originalName);
      return {
        text: extractedText,
        classification: classification,
        duplicateAnalysis: duplicateAnalysis,
        structureAnalysis: structureAnalysis,
        processingMethod: this.isScannedPDF(data.text) ? 'Vision API OCR' : 'Standard PDF'
      };
    } catch (error) {
      console.error('‚ùå Error in enhanced document processing:', error);
      throw error;
    }
  }
}

module.exports = new VisionOCRService(); 